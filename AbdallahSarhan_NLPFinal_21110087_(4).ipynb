{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9b7ee026",
      "metadata": {
        "id": "9b7ee026"
      },
      "source": [
        "# NLP Final Project"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install package"
      ],
      "metadata": {
        "id": "NXBqRgG3digt"
      },
      "id": "NXBqRgG3digt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JASpYAjehiS2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "JASpYAjehiS2",
        "outputId": "9147025c-1a51-43fb-9f3b-e8b7846b9485"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.3\n",
            "    Uninstalling scipy-1.15.3:\n",
            "      Successfully uninstalled scipy-1.15.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "5a0882818ea74e499c3ec4962a0d74ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.6.15)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m^C\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim\n",
        "!pip install tensorflow\n",
        "!pip install fasttext"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c22ce589",
      "metadata": {
        "id": "c22ce589"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "72e1bb5f",
      "metadata": {
        "id": "72e1bb5f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "import gensim.downloader as api\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, Dropout\n",
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
        "from transformers import AutoTokenizer, TFAutoModel, TFAutoModelForSequenceClassification\n",
        "import torch\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import nltk\n",
        "import re\n",
        "from nltk.stem.isri import ISRIStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, Dropout\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification, create_optimizer\n",
        "from sklearn.metrics import precision_score, f1_score, classification_report\n",
        "from tensorflow.keras.layers import Dense, LSTM, GRU, Dropout, Reshape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "11c2cd83",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "11c2cd83",
        "outputId": "e1e8ab7d-47c4-487b-d55b-a679d613d506"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            text  label\n",
              "0                                   استشاره عيون     23\n",
              "1           السلام عليكم ممكن دكتور مفاصل واعصاب     14\n",
              "2  عندي نقص فيتامين د هل ممكن استخدم معه كالسيوم     14\n",
              "3                             عمليه الحول للكبار     23\n",
              "4                      ألم بالكتف الايسر من فترة     14"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc7c755c-87ec-4d19-b64c-6f00f9d28fcc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>استشاره عيون</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>السلام عليكم ممكن دكتور مفاصل واعصاب</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>عندي نقص فيتامين د هل ممكن استخدم معه كالسيوم</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>عمليه الحول للكبار</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ألم بالكتف الايسر من فترة</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc7c755c-87ec-4d19-b64c-6f00f9d28fcc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dc7c755c-87ec-4d19-b64c-6f00f9d28fcc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dc7c755c-87ec-4d19-b64c-6f00f9d28fcc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a0382134-de18-41dd-ac21-2c8865bce122\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a0382134-de18-41dd-ac21-2c8865bce122')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a0382134-de18-41dd-ac21-2c8865bce122 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 92559,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 82222,\n        \"samples\": [\n          \"\\u0627\\u0639\\u0627\\u0646\\u064a \\u0645\\u0646 \\u062f\\u0648\\u062e\\u0647 \\u0645\\u062a\\u0642\\u0637\\u0639\\u0647 \\u0648\\u0627\\u0639\\u0627\\u0646\\u064a \\u0645\\u0646 \\u062d\\u0645\\u062f\\u0627\\u0646 \\u0641\\u064a \\u0627\\u0644\\u062c\\u0633\\u062f \\u063a\\u064a\\u0631 \\u0645\\u0633\\u062a\\u0645\\u0631 \\u0648\\u0627\\u0639\\u0627\\u0646\\u064a \\u0645\\u0646 \\u062a\\u0646\\u0645\\u064a\\u0644 \\u0641\\u064a \\u0643\\u0641 \\u0627\\u0644\\u064a\\u062f\\u064a\\u0646 \\u063a\\u064a\\u0631 \\u0645\\u0633\\u062a\\u0645\\u0631\",\n          \"\\u062c\\u0641\\u0646 \\u0628\\u062a\\u0639 \\u0639\\u064a\\u0646\\u064a \\u0627\\u0644\\u0644\\u064a \\u0641\\u0648\\u0642 \\u0643\\u0644 \\u0634\\u0648\\u064a\\u0647 \\u064a\\u062c\\u0644\\u064a \\u0631\\u0639\\u0634\\u0647 \\u062a\\u0631\\u0648\\u062d \\u0648\\u062a\\u062c\\u064a \\u062e\\u0627\\u064a\\u0641\\u0647 \\u062c\\u062f\\u0627 \\u0633\\u0628\\u0628\\u0648 \\u0627\\u064a\\u0647\",\n          \"\\u062f\\u0642\\u0627\\u062a \\u0642\\u0644\\u0628 \\u0633\\u0631\\u064a\\u0639\\u0647 \\u0648\\u0639\\u062f\\u0645 \\u0627\\u0633\\u062a\\u0646\\u0634\\u0627\\u0642 \\u0627\\u0644\\u0646\\u0641\\u0633 \\u0628\\u0633\\u0647\\u0648\\u0644\\u0647 \\u0648\\u0634\\u0628\\u0647 \\u062f\\u0648\\u062e\\u0647\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29,\n        \"min\": 14,\n        \"max\": 91,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          14,\n          91,\n          18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "df = pd.read_csv('/content/altibbi_specialty_data.csv')[[\"question_body\", \"specialty_id\"]].dropna()\n",
        "df.columns = [\"text\", \"label\"]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5e0a1a69",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e0a1a69",
        "outputId": "c337847e-8db8-4cee-dcc0-ef8ff6a2feb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preprocessed sentence: سلم علي مكن دكتور فصل عصب\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "\n",
        "stemmer = ISRIStemmer()\n",
        "arabic_stopwords = set(stopwords.words(\"arabic\"))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r\"[إأآا]\", \"ا\", text)\n",
        "    text = re.sub(r\"ى\", \"ي\", text)\n",
        "    text = re.sub(r\"ؤ\", \"و\", text)\n",
        "    text = re.sub(r\"ئ\", \"ي\", text)\n",
        "    text = re.sub(r\"ة\", \"ه\", text)\n",
        "    text = re.sub(r\"[^\\u0600-\\u06FF\\s]\", \"\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    tokens = [stemmer.stem(w) for w in text.split() if w not in arabic_stopwords and len(w) > 1]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "df['text'] = df['text'].apply(preprocess_text)\n",
        "print(\"preprocessed sentence:\", df['text'].iloc[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['text']\n",
        "y = df['label']"
      ],
      "metadata": {
        "id": "mBAsd4PUuxYO"
      },
      "id": "mBAsd4PUuxYO",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_fraction = 0.3\n",
        "X_sample = X.sample(frac=sample_fraction, random_state=42)\n",
        "y_sample = y.loc[X_sample.index]"
      ],
      "metadata": {
        "id": "J4NiJgyjuhyW"
      },
      "id": "J4NiJgyjuhyW",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4d8bb506",
      "metadata": {
        "id": "4d8bb506"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train size:\", len(X_train))\n",
        "print(\"Test size:\", len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVFkfZGeQNZ3",
        "outputId": "4f029b79-c3e4-4939-b758-ead707f3b7d4"
      },
      "id": "tVFkfZGeQNZ3",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 22214\n",
            "Test size: 5554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "y_train_enc = le.fit_transform(y_train)\n",
        "y_test_enc = le.transform(y_test)"
      ],
      "metadata": {
        "id": "mHPzh3JlFr5M"
      },
      "id": "mHPzh3JlFr5M",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bert , Fasttext , TFIDF , BOW"
      ],
      "metadata": {
        "id": "mxBWsLo4SG-N"
      },
      "id": "mxBWsLo4SG-N"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -c https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ar.300.vec.gz\n",
        "\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "fasttext_model = KeyedVectors.load_word2vec_format(\"cc.ar.300.vec.gz\", binary=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21smvN8_kOQy",
        "outputId": "d9f1898d-89da-4a14-d8c9-dcfd9c6b09a2"
      },
      "id": "21smvN8_kOQy",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-02 05:41:44--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ar.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.167.112.129, 3.167.112.51, 3.167.112.66, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.167.112.129|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1272365870 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‘cc.ar.300.vec.gz’\n",
            "\n",
            "cc.ar.300.vec.gz    100%[===================>]   1.18G  96.2MB/s    in 11s     \n",
            "\n",
            "2025-07-02 05:41:55 (114 MB/s) - ‘cc.ar.300.vec.gz’ saved [1272365870/1272365870]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_ml_model(vectorizer, model):\n",
        "    X_train_vec = vectorizer.fit_transform(X_train)\n",
        "    X_test_vec = vectorizer.transform(X_test)\n",
        "    model.fit(X_train_vec, y_train_enc)\n",
        "    preds = model.predict(X_test_vec)\n",
        "    return accuracy_score(y_test_enc, preds)\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features=1000)\n",
        "bow = CountVectorizer(max_features=1000)\n",
        "log_reg = LogisticRegression()\n",
        "rf = RandomForestClassifier(n_estimators=10)\n",
        "\n",
        "results = []\n",
        "for name, vec in [(\"TF-IDF\", tfidf), (\"BOW\", bow)]:\n",
        "    for model_name, model in [(\"Logistic Regression\", log_reg), (\"Random Forest\", rf)]:\n",
        "        acc = evaluate_ml_model(vec, model)\n",
        "        results.append((name, model_name, acc))"
      ],
      "metadata": {
        "id": "fU1t7ust5NIf"
      },
      "id": "fU1t7ust5NIf",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fasttext_embed(texts):\n",
        "    embeddings = []\n",
        "    for text in texts:\n",
        "        vecs = [fasttext_model[word] for word in text.split() if word in fasttext_model]\n",
        "        if vecs:\n",
        "            embeddings.append(np.mean(vecs, axis=0))\n",
        "        else:\n",
        "            embeddings.append(np.zeros(300))\n",
        "    return np.array(embeddings)\n",
        "\n",
        "X_train_ft = fasttext_embed(X_train)\n",
        "X_test_ft = fasttext_embed(X_test)\n",
        "\n",
        "\n",
        "for model_name, model in [(\"Logistic Regression\", log_reg), (\"Random Forest\", rf)]:\n",
        "    model.fit(X_train_ft, y_train_enc)\n",
        "    preds = model.predict(X_test_ft)\n",
        "    acc = accuracy_score(y_test_enc, preds)\n",
        "    results.append((\"FastText\", model_name, acc))\n"
      ],
      "metadata": {
        "id": "WqAkJ3fnSS3E"
      },
      "id": "WqAkJ3fnSS3E",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model_name = \"aubmindlab/bert-base-arabertv2\"\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
        "bert_model = TFAutoModel.from_pretrained(bert_model_name)\n",
        "\n",
        "def get_bert_cls_embeddings(texts, tokenizer, model, batch_size=16, max_len=128):\n",
        "    all_embeddings = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch = texts[i:i+batch_size]\n",
        "        encodings = tokenizer(batch, truncation=True, padding=True, return_tensors=\"tf\", max_length=max_len)\n",
        "        outputs = model(encodings[\"input_ids\"], attention_mask=encodings[\"attention_mask\"])\n",
        "        cls_embeddings = outputs.last_hidden_state[:, 0, :].numpy()\n",
        "        all_embeddings.append(cls_embeddings)\n",
        "        print(f\"Processed batch {i//batch_size + 1} / {len(texts)//batch_size + 1}\")\n",
        "    return np.vstack(all_embeddings)\n",
        "\n",
        "X_train_bert = get_bert_cls_embeddings(X_train.tolist()[:200], bert_tokenizer, bert_model)\n",
        "X_test_bert = get_bert_cls_embeddings(X_test.tolist()[:50], bert_tokenizer, bert_model)\n",
        "\n",
        "y_train_enc_small = y_train_enc[:200]\n",
        "y_test_enc_small = y_test_enc[:50]\n",
        "\n",
        "\n",
        "for model_name, model in [(\"Logistic Regression\", log_reg), (\"Random Forest\", rf)]:\n",
        "    model.fit(X_train_bert, y_train_enc_small)\n",
        "    preds = model.predict(X_test_bert)\n",
        "    acc = accuracy_score(y_test_enc_small, preds)\n",
        "    results.append((\"BERT\", model_name, acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WV_NGNaDSW7r",
        "outputId": "b4a8d250-cc46-4830-e8ed-5c2866dd85e6"
      },
      "id": "WV_NGNaDSW7r",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'bert.embeddings.position_ids', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 1 / 13\n",
            "Processed batch 2 / 13\n",
            "Processed batch 3 / 13\n",
            "Processed batch 4 / 13\n",
            "Processed batch 5 / 13\n",
            "Processed batch 6 / 13\n",
            "Processed batch 7 / 13\n",
            "Processed batch 8 / 13\n",
            "Processed batch 9 / 13\n",
            "Processed batch 10 / 13\n",
            "Processed batch 11 / 13\n",
            "Processed batch 12 / 13\n",
            "Processed batch 13 / 13\n",
            "Processed batch 1 / 4\n",
            "Processed batch 2 / 4\n",
            "Processed batch 3 / 4\n",
            "Processed batch 4 / 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_dl_model(X_train_array, X_test_array, y_train, y_test, mode=\"LSTM\"):\n",
        "    model = Sequential()\n",
        "    model.add(Reshape((1, X_train_array.shape[1]), input_shape=(X_train_array.shape[1],)))\n",
        "    if mode == \"LSTM\":\n",
        "        model.add(LSTM(64))\n",
        "    elif mode == \"GRU\":\n",
        "        model.add(GRU(64))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(len(np.unique(y_train)), activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(X_train_array, y_train, epochs=1, batch_size=16, verbose=0)\n",
        "    loss, acc = model.evaluate(X_test_array, y_test, verbose=0)\n",
        "    return acc\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features=500)\n",
        "bow = CountVectorizer(max_features=500)\n",
        "\n",
        "X_train_tfidf = tfidf.fit_transform(X_train).toarray()\n",
        "X_test_tfidf = tfidf.transform(X_test).toarray()\n",
        "X_train_bow = bow.fit_transform(X_train).toarray()\n",
        "X_test_bow = bow.transform(X_test).toarray()\n",
        "\n",
        "def fasttext_embed(texts):\n",
        "    embeddings = []\n",
        "    for text in texts:\n",
        "        vecs = [fasttext_model[word] for word in text.split() if word in fasttext_model]\n",
        "        if vecs:\n",
        "            embeddings.append(np.mean(vecs, axis=0))\n",
        "        else:\n",
        "            embeddings.append(np.zeros(300))\n",
        "    return np.array(embeddings)\n",
        "\n",
        "X_train_ft = fasttext_embed(X_train)\n",
        "X_test_ft = fasttext_embed(X_test)\n",
        "\n",
        "for emb_name, X_tr, X_te in [\n",
        "    (\"TF-IDF\", X_train_tfidf, X_test_tfidf),\n",
        "    (\"BOW\", X_train_bow, X_test_bow),\n",
        "    (\"FastText\", X_train_ft, X_test_ft)\n",
        "]:\n",
        "    for mode in [\"LSTM\", \"GRU\"]:\n",
        "        acc = run_dl_model(X_tr, X_te, y_train_enc, y_test_enc, mode=mode)\n",
        "        results.append((emb_name, mode, acc))\n",
        "\n",
        "for mode in [\"LSTM\", \"GRU\"]:\n",
        "    acc = run_dl_model(X_train_bert, X_test_bert, y_train_enc_small, y_test_enc_small, mode=mode)\n",
        "    results.append((\"BERT\", mode, acc))"
      ],
      "metadata": {
        "id": "GbtM0VREXhlZ"
      },
      "id": "GbtM0VREXhlZ",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame(results, columns=[\"Embedding\", \"Model\", \"Accuracy\"])\n",
        "results_df = results_df.sort_values(by=\"Accuracy\", ascending=False).reset_index(drop=True)\n",
        "print(\"    Accuracy Results for Embeddings - Models\\n\")\n",
        "print(results_df.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPJaPOfzbDlh",
        "outputId": "dcc0ced2-dd2c-47a9-de8b-87367f26e17b"
      },
      "id": "HPJaPOfzbDlh",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Accuracy Results for Embeddings - Models\n",
            "\n",
            "Embedding               Model  Accuracy\n",
            "   TF-IDF Logistic Regression  0.877926\n",
            "      BOW Logistic Regression  0.870904\n",
            "      BOW                LSTM  0.860281\n",
            "   TF-IDF                LSTM  0.858300\n",
            "      BOW                 GRU  0.857400\n",
            "   TF-IDF       Random Forest  0.853979\n",
            "      BOW       Random Forest  0.852539\n",
            "   TF-IDF                 GRU  0.852539\n",
            "     BERT Logistic Regression  0.640000\n",
            " FastText       Random Forest  0.524847\n",
            " FastText Logistic Regression  0.523407\n",
            " FastText                 GRU  0.515124\n",
            " FastText                LSTM  0.498019\n",
            "     BERT       Random Forest  0.460000\n",
            "     BERT                 GRU  0.360000\n",
            "     BERT                LSTM  0.340000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Arabic Bert"
      ],
      "metadata": {
        "id": "uhb-5AARRuX4"
      },
      "id": "uhb-5AARRuX4"
    },
    {
      "cell_type": "code",
      "source": [
        "bert_tokenizer = AutoTokenizer.from_pretrained(\"aubmindlab/bert-base-arabertv2\")\n",
        "\n",
        "def encode_bert_texts(texts, tokenizer, max_len=64):\n",
        "    return tokenizer(list(texts), padding=True, truncation=True, max_length=max_len, return_tensors=\"tf\")\n",
        "\n",
        "train_bert = encode_bert_texts(X_train, bert_tokenizer)\n",
        "test_bert = encode_bert_texts(X_test, bert_tokenizer)\n",
        "\n",
        "bert_model = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "    \"aubmindlab/bert-base-arabertv2\",\n",
        "    num_labels=len(le.classes_)\n",
        ")\n",
        "optimizer, _ = create_optimizer(init_lr=2e-5, num_train_steps=100, num_warmup_steps=10)\n",
        "\n",
        "\n",
        "bert_model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "\n",
        "bert_model.fit(train_bert.data, y_train_enc, epochs=2, batch_size=16)\n",
        "\n",
        "bert_result = bert_model.evaluate(test_bert.data, y_test_enc)\n",
        "print(f\"\\nArabic BERT Accuracy: {bert_result[1]:.4f}\")\n",
        "\n",
        "preds = bert_model.predict(test_bert.data).logits\n",
        "pred_classes = np.argmax(preds, axis=1)\n",
        "\n",
        "precision = precision_score(y_test_enc, pred_classes, average='weighted')\n",
        "f1 = f1_score(y_test_enc, pred_classes, average='weighted')\n",
        "\n",
        "print(f\"Arabic BERT Precision: {precision:.4f}\")\n",
        "print(f\"Arabic BERT F1 Score: {f1:.4f}\")\n",
        "\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_enc, pred_classes, target_names=le.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BJ91lVHReA7",
        "outputId": "aae6d7eb-5bb7-499e-d0ae-bd313d35fd2e"
      },
      "id": "0BJ91lVHReA7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['bert.embeddings.position_ids']\n",
            "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1389/1389 [==============================] - 20124s 14s/step - loss: 1.4787 - accuracy: 0.4079\n",
            "Epoch 2/2\n",
            " 776/1389 [===============>..............] - ETA: 2:27:54 - loss: 1.4718 - accuracy: 0.4075"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Arabic GPT"
      ],
      "metadata": {
        "id": "yjAc-71AR1-V"
      },
      "id": "yjAc-71AR1-V"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "gpt_tokenizer = AutoTokenizer.from_pretrained(\"aubmindlab/gpt2-base-arabic\")\n",
        "gpt_model = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "    \"aubmindlab/gpt2-base-arabic\",\n",
        "    num_labels=len(le.classes_)\n",
        ")\n",
        "\n",
        "gpt_tokenizer.pad_token = gpt_tokenizer.eos_token\n",
        "\n",
        "def encode_gpt_texts(texts, tokenizer, max_len=64):\n",
        "    return tokenizer(list(texts), padding=True, truncation=True, max_length=max_len, return_tensors=\"tf\")\n",
        "\n",
        "train_gpt = encode_gpt_texts(X_train, gpt_tokenizer)\n",
        "test_gpt = encode_gpt_texts(X_test, gpt_tokenizer)\n",
        "\n",
        "gpt_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "gpt_model.fit(train_gpt.data, y_train_enc, epochs=2, batch_size=16)\n",
        "\n",
        "gpt_result = gpt_model.evaluate(test_gpt.data, y_test_enc)\n",
        "print(f\"Arabic GPT Accuracy: {gpt_result[1]:.4f}\")\n",
        "\n",
        "preds = gpt_model.predict(test_gpt.data).logits\n",
        "pred_classes = np.argmax(preds, axis=1)\n",
        "\n",
        "precision = precision_score(y_test_enc, pred_classes, average='weighted')\n",
        "f1 = f1_score(y_test_enc, pred_classes, average='weighted')\n",
        "\n",
        "print(f\"Arabic GPT Precision: {precision:.4f}\")\n",
        "print(f\"Arabic GPT F1 Score: {f1:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_enc, pred_classes, target_names=le.classes_))"
      ],
      "metadata": {
        "id": "FwyS5vXoRrtL"
      },
      "id": "FwyS5vXoRrtL",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "NXBqRgG3digt",
        "c22ce589",
        "uhb-5AARRuX4",
        "yjAc-71AR1-V"
      ]
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}